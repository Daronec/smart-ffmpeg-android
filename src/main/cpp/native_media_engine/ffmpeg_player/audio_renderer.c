#include "audio_renderer.h"
#include "audio_render_android.h"  // –¥–ª—è audio_render_get_latency
#include "ffmpeg_player.h"
#include "avsync_gate.h"  // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: AVSYNC-IMPLEMENTATION
#include "libavutil/avutil.h"  // –¥–ª—è AV_NOPTS_VALUE
#include "libavutil/frame.h"  // –¥–ª—è frame->best_effort_timestamp
#include "libavutil/rational.h"  // –¥–ª—è av_q2d
#include "libavutil/time.h"  // –¥–ª—è av_gettime
#include <jni.h>
#include <stdlib.h>
#include <string.h>
#include <math.h>
#include <unistd.h>
#include <stdbool.h>
#include <android/log.h>
#undef pause  // –£–±–∏—Ä–∞–µ–º –∫–æ–Ω—Ñ–ª–∏–∫—Ç —Å —Å–∏—Å—Ç–µ–º–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–µ–π pause() –∏–∑ unistd.h

#define LOG_TAG "AudioRenderer"
#define ALOGE(...) __android_log_print(ANDROID_LOG_ERROR, LOG_TAG, __VA_ARGS__)
#define ALOGI(...) __android_log_print(ANDROID_LOG_INFO,  LOG_TAG, __VA_ARGS__)
#define ALOGW(...) __android_log_print(ANDROID_LOG_WARN,  LOG_TAG, __VA_ARGS__)
#define ALOGD(...) __android_log_print(ANDROID_LOG_DEBUG, LOG_TAG, __VA_ARGS__)

/// üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: AUDIO CLOCK SOURCE FIX - –ø–æ–ª—É—á–∏—Ç—å monotonic time –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
/// –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è —Ä–∞—Å—á—ë—Ç–∞ elapsed time –≤ audio clock
static double get_monotonic_time_sec(void) {
    return (double)av_gettime_relative() / 1000000.0;  // –º–∏–∫—Ä–æ—Å–µ–∫—É–Ω–¥—ã ‚Üí —Å–µ–∫—É–Ω–¥—ã
}

// –ú–∞–∫—Ä–æ—Å—ã –¥–ª—è FFmpeg
#define FFMAX(a, b) ((a) > (b) ? (a) : (b))
// FFMIN —É–∂–µ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω –≤ libavutil/macros.h

/// –ü–æ—Ç–æ–∫ —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–∞ –∞—É–¥–∏–æ (MASTER CLOCK)
///
/// üéØ –¢–û–õ–¨–ö–û –∑–¥–µ—Å—å –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è audio_clock –Ω–∞ –æ—Å–Ω–æ–≤–µ samples_written
/// –ò–∑–≤–ª–µ–∫–∞–µ—Ç PCM frames –∏–∑ FrameQueue –∏ –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç –≤ AudioTrack —á–µ—Ä–µ–∑ audio_render_android
static void *audio_render_thread(void *arg) {
    AudioState *as = (AudioState *)arg;
    
    while (!as->abort) {
        // üî¥ –ó–ê–î–ê–ß–ê 1: Guard –¥–ª—è pause - audio thread –Ω–µ –ø–∏—à–µ—Ç –ø—Ä–∏ –ø–∞—É–∑–µ
        if (as->paused) {
            usleep(5000); // 5ms
            continue;
        }
        
        // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: Audio sync rules - audio –Ω–µ –∏–≥—Ä–∞–µ—Ç –≤–ø–µ—Ä—ë–¥, –¥–æ–≥–æ–Ω—è–µ—Ç –≤–∏–¥–µ–æ
        // –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –∂–¥–∞—Ç—å –≤–∏–¥–µ–æ –∏–ª–∏ –¥—Ä–æ–ø–Ω—É—Ç—å –∞—É–¥–∏–æ
        bool audio_waiting_for_video = false;
        bool should_drop_audio = false;
        
        if (as->player_ctx) {
            PlayerContext *ctx = (PlayerContext *)as->player_ctx;
            
            // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: AUDIO CLOCK SOURCE FIX - –®–ê–ì 16: –ò—Å–ø–æ–ª—å–∑—É–µ–º audio_get_clock()
            // –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–π audio clock (–∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏–π, PTS-based)
            extern double audio_get_clock(AudioState *as);
            double audio_clock_sec = audio_get_clock(ctx->audio);
            double audio_pts_ms = isnan(audio_clock_sec) ? 0.0 : audio_clock_sec * 1000.0;
            
            // –ü–æ–ª—É—á–∞–µ–º master clock (video PTS) –∏–∑ PlayerContext
            double master_clock_ms = (double)ctx->master_clock_ms;
            
            // –í—ã—á–∏—Å–ª—è–µ–º delta (—Ä–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É audio –∏ video)
            double delta_ms = audio_pts_ms - master_clock_ms;
            
            // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: Audio sync rule 1 - audio –Ω–µ –∏–≥—Ä–∞–µ—Ç –≤–ø–µ—Ä—ë–¥
            // –ï—Å–ª–∏ audio –≤–ø–µ—Ä–µ–¥–∏ video –±–æ–ª–µ–µ —á–µ–º –Ω–∞ 40ms - –∂–¥—ë–º –≤–∏–¥–µ–æ (fill_silence)
            if (delta_ms > 40.0) {
                audio_waiting_for_video = true;
            }
            
            // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: Audio sync rule 2 - drop audio –µ—Å–ª–∏ —Å–∏–ª—å–Ω–æ –æ—Ç—Å—Ç–∞—ë—Ç
            // –ï—Å–ª–∏ audio –æ—Ç—Å—Ç–∞—ë—Ç –æ—Ç video –±–æ–ª–µ–µ —á–µ–º –Ω–∞ 80ms - –¥—Ä–æ–ø–∞–µ–º –∫–∞–¥—Ä
            if (delta_ms < -80.0) {
                should_drop_audio = true;
            }
        }
        
        // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: –ï—Å–ª–∏ audio –≤–ø–µ—Ä–µ–¥–∏ –≤–∏–¥–µ–æ - fill_silence –≤–º–µ—Å—Ç–æ –∑–∞–ø–∏—Å–∏
        if (audio_waiting_for_video) {
            // –ñ–¥—ë–º –≤–∏–¥–µ–æ - –Ω–µ –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –∞—É–¥–∏–æ, –ø—Ä–æ—Å—Ç–æ –∂–¥—ë–º
            usleep(5000); // 5ms
            continue;
        }
        
        // –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–∞–¥—Ä –∏–∑ –æ—á–µ—Ä–µ–¥–∏ (–±–ª–æ–∫–∏—Ä—É—é—â–∏–π)
        Frame af;
        if (frame_queue_pop(as->frameQueue, &af, true) <= 0) {
            continue;
        }
        
        AVFrame *frame = af.frame;
        double frame_pts = af.pts;  // PTS –∫–∞–¥—Ä–∞ (–∏–∑ decode thread)
        
        // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: –ï—Å–ª–∏ audio —Å–∏–ª—å–Ω–æ –æ—Ç—Å—Ç–∞—ë—Ç - –¥—Ä–æ–ø–∞–µ–º –∫–∞–¥—Ä
        if (should_drop_audio) {
            ALOGW("üîä Audio sync: dropping frame (audio behind video by > 80ms)");
            av_frame_free(&frame);
            continue;
        }
        
        // –ü–æ–ª—É—á–∞–µ–º PCM –¥–∞–Ω–Ω—ã–µ –∏–∑ –∫–∞–¥—Ä–∞
        int pcm_size = frame->nb_samples * as->channels * 2; // S16, stereo
        uint8_t *pcm = frame->data[0];
        
        // –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ AudioTrack (—á–µ—Ä–µ–∑ audio_render_android)
        int written = audio_render_write(&as->audio_render, pcm, pcm_size);
        
        if (written > 0) {
            // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: AUDIO CLOCK SOURCE FIX - –®–ê–ì 16.2
            // üîä –ì–î–ï –û–ë–ù–û–í–õ–Ø–ï–ú AUDIO CLOCK (–ï–î–ò–ù–°–¢–í–ï–ù–ù–û–ï –ú–ï–°–¢–û)
            // –ø–æ—Å–ª–µ AudioTrack.write(...)
            // üö´ –ù–ò–ì–î–ï –±–æ–ª—å—à–µ clock –Ω–µ —Ç—Ä–æ–≥–∞–µ–º
            
            // –ü–æ–ª—É—á–∞–µ–º PTS —Ñ—Ä–µ–π–º–∞ (—É–∂–µ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö –∏–∑ decode thread)
            // frame_pts —É–∂–µ –≤—ã—á–∏—Å–ª–µ–Ω –≤—ã—à–µ: double frame_pts = af.pts;
            
            // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: AUDIO CLOCK SOURCE FIX - –®–ê–ì 16.2: –û–ë–ù–û–í–õ–ï–ù–ò–ï AUDIO CLOCK
            // –ï—Å–ª–∏ PTS –≤–∞–ª–∏–¥–µ–Ω - –æ–±–Ω–æ–≤–ª—è–µ–º clock —Å —É—á–µ—Ç–æ–º duration –∏ latency
            if (!isnan(frame_pts) && frame_pts >= 0.0) {
                // –í—ã—á–∏—Å–ª—è–µ–º duration —Ñ—Ä–µ–π–º–∞
                double frame_duration = frame->nb_samples / (double)as->sample_rate;
                
                // –û–±–Ω–æ–≤–ª—è–µ–º clock —Å–æ–≥–ª–∞—Å–Ω–æ –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–æ–º—É –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—é:
                // audio_clock = last_audio_frame_pts + last_audio_frame_duration - audio_latency_compensation
                as->clock.last_pts = frame_pts;
                as->clock.last_duration = frame_duration;
                as->clock.last_update_us = av_gettime_relative();  // –º–∏–∫—Ä–æ—Å–µ–∫—É–Ω–¥—ã
                
                // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: AUDIO CLOCK SOURCE FIX - –®–ê–ì 16.1: –ö–ê–ù–û–ù–ò–ß–ï–°–ö–û–ï –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï
                // audio_clock = last_audio_frame_pts + last_audio_frame_duration - audio_latency_compensation
                // Latency –∫–æ–º–ø–µ–Ω—Å–∏—Ä—É–µ—Ç—Å—è, —á—Ç–æ–±—ã clock —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞–ª —Ç–æ–º—É, —á—Ç–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –°–õ–´–®–ò–¢
                as->clock.clock = frame_pts + frame_duration - as->clock.latency;
                as->clock.valid = 1;
                
                // üîç –ò–ù–°–¢–†–£–ú–ï–ù–¢–ê–¶–ò–Ø: –ª–æ–≥–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 10 –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π
                static int log_count = 0;
                if (log_count < 10) {
                    ALOGD("üîä AudioClock: clock=%.3f (pts=%.3f, duration=%.3f, latency=%.3f)", 
                          as->clock.clock, frame_pts, frame_duration, as->clock.latency);
                    log_count++;
                }
            }
            
            // –ü—Ä–æ–≤–µ—Ä—è–µ–º stall (Huawei case)
            audio_check_stall(as);
            
            // –û–±–Ω–æ–≤–ª—è–µ–º PlayerContext->avsync.audio_clock –∏–∑ clock.clock
            if (as->player_ctx) {
                PlayerContext *ctx = (PlayerContext *)as->player_ctx;
                bool was_invalid = !ctx->avsync.audio_healthy;
                
                // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: AUDIO CLOCK SOURCE FIX - –®–ê–ì 16: –ò—Å–ø–æ–ª—å–∑—É–µ–º clock.clock (–Ω–µ pts_sec)
                // –û–±–Ω–æ–≤–ª—è–µ–º avsync.audio_clock –∏–∑ clock.clock (–∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏–π audio clock)
                ctx->avsync.audio_clock = as->clock.clock;
                ctx->avsync.audio_healthy = as->clock.valid && !audio_clock_is_stalled(&as->clock);
                ctx->avsync.last_audio_clock = as->clock.clock;
                ctx->avsync.last_audio_clock_ts = (int64_t)(as->clock.last_update_us / 1000);  // microseconds ‚Üí ms
                
                // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: AVSYNC IMPLEMENTATION - –®–ê–ì 4
                // –ï—Å–ª–∏ audio clock —Å—Ç–∞–ª –≤–∞–ª–∏–¥–Ω—ã–º ‚Üí –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º master –Ω–∞ AUDIO
                if (was_invalid && ctx->avsync.audio_healthy) {
                    // –ü–µ—Ä–≤—ã–π audio clock update ‚Üí clock –≤–∞–ª–∏–¥–µ–Ω ‚Üí –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º master –Ω–∞ AUDIO
                    if (ctx->has_audio == 1) {
                        ctx->avsync.master = CLOCK_MASTER_AUDIO;
                        ALOGI("‚úÖ AVSYNC: Master switch VIDEO ‚Üí AUDIO (audio_clock became valid: %.3f)", 
                              ctx->avsync.audio_clock);
                        
                        // –û–±–Ω–æ–≤–ª—è–µ–º AVSyncGate
                        avsync_gate_set_master(&ctx->avsync_gate, AVSYNC_MASTER_AUDIO_GATE);
                        avsync_gate_set_valid(&ctx->avsync_gate);
                    }
                }
                
                // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: AVSYNC-IMPLEMENTATION - Audio clock advance (guarded)
                // –û–±–Ω–æ–≤–ª—è–µ–º audio clock –≤ AVSyncGate –¢–û–õ–¨–ö–û –µ—Å–ª–∏ gate –æ—Ç–∫—Ä—ã—Ç
                if (avsync_gate_is_open(&ctx->avsync_gate)) {
                    int64_t clock_us = (int64_t)(as->clock.clock * 1000000.0);
                    avsync_gate_update_audio_clock(&ctx->avsync_gate, clock_us);
                }
                
                // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: AVSYNC HARDENING - –æ–±–Ω–æ–≤–ª—è–µ–º master switch –ª–æ–≥–∏–∫—É
                extern void avsync_update(PlayerContext *ctx);
                avsync_update(ctx);
                
                // üîç –ò–ù–°–¢–†–£–ú–ï–ù–¢–ê–¶–ò–Ø: –ª–æ–≥–∏—Ä—É–µ–º audio clock (–ø–µ—Ä–≤—ã–µ 10 –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π)
                static int audio_clock_log_count = 0;
                if (audio_clock_log_count < 10) {
                    ALOGD("üîä AUDIO_CLOCK: %.3f (PTS-based, canonical)", as->clock.clock);
                    audio_clock_log_count++;
                }
                
                // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: AUDIO CLOCK SOURCE FIX - –®–ê–ì 16.8: ASSERT (–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–´)
                #ifdef DEBUG
                static double last_audio_clock = 0.0;
                // ASSERT(!isnan(audio_clock))
                if (as->clock.valid && isnan(as->clock.clock)) {
                    ALOGE("‚ùå AVSYNC_ASSERT FAILED: audio_clock is NAN (FATAL)");
                    abort(); // üî• FATAL –≤ debug
                }
                // ASSERT(audio_clock >= 0)
                if (as->clock.valid && as->clock.clock < 0.0) {
                    ALOGE("‚ùå AVSYNC_ASSERT FAILED: audio_clock < 0 (%.3f) (FATAL)", as->clock.clock);
                    abort(); // üî• FATAL –≤ debug
                }
                // ASSERT(audio_clock monotonic)
                if (as->clock.valid && !isnan(as->clock.clock) && as->clock.clock < last_audio_clock - 0.001) {
                    ALOGE("‚ùå AVSYNC_ASSERT FAILED: audio_clock regression (%.3f < %.3f) (FATAL)", 
                          as->clock.clock, last_audio_clock);
                    abort(); // üî• FATAL –≤ debug
                }
                if (as->clock.valid && !isnan(as->clock.clock)) {
                    last_audio_clock = as->clock.clock;
                }
                
                if (!as->clock.valid) {
                    ALOGE("‚ùå AVSYNC_ASSERT FAILED: audio_clock is invalid");
                }
                #endif
            }
            
            // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: AUDIO-NATIVE Contract - —Ç–æ—á–∫–∞ –ø–µ—Ä–µ—Ö–æ–¥–∞ AUDIO_READY
            // –ü–æ—Å–ª–µ –ø–µ—Ä–≤–æ–π —É—Å–ø–µ—à–Ω–æ–π –∑–∞–ø–∏—Å–∏ ‚Üí AUDIO_READY (buffer primed)
            if (as->player_ctx) {
                PlayerContext *ctx = (PlayerContext *)as->player_ctx;
                if (ctx->audio_state == AUDIO_INITIALIZED) {
                    ctx->audio_state = AUDIO_READY;
                    ALOGI("üéß AudioState: AUDIO_INITIALIZED ‚Üí AUDIO_READY (buffer primed, first frame written)");
                    extern void native_player_emit_audio_state_event(const char *state);
                    native_player_emit_audio_state_event("ready");
                }
            }
            
            // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: AUDIO CLOCK SOURCE FIX - –®–ê–ì 16.5: –ß–¢–û –ó–ê–ü–†–ï–©–ï–ù–û
            // ‚ùå –ó–∞–ø—Ä–µ—â–µ–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å getPlaybackHeadPosition –∫–∞–∫ –∏—Å—Ç–æ—á–Ω–∏–∫ clock
            // ‚ùå –ó–∞–ø—Ä–µ—â–µ–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å systemClock
            // ‚ùå –ó–∞–ø—Ä–µ—â–µ–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å audio callback
            // ‚ùå –ó–∞–ø—Ä–µ—â–µ–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–∞–π–º–µ—Ä—ã
            // ‚ùå –ó–∞–ø—Ä–µ—â–µ–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å sleep
            // Clock –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è –¢–û–õ–¨–ö–û –Ω–∞ –æ—Å–Ω–æ–≤–µ PTS –ø—Ä–∏ write (—Å–º. –∫–æ–¥ –≤—ã—à–µ, –≥–¥–µ clock –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è –ø—Ä–∏ written > 0)
            // Playback head –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¢–û–õ–¨–ö–û –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ AudioState, –ù–ï –¥–ª—è clock
            
            // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: AudioState Contract (RFC v1) - –ø—Ä–æ–≤–µ—Ä—è–µ–º AudioTrack —Å–æ—Å—Ç–æ—è–Ω–∏–µ
            // –ò—Å–ø–æ–ª—å–∑—É–µ–º getPlaybackHeadPosition –¢–û–õ–¨–ö–û –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏, –ù–ï –¥–ª—è clock
            if (as->player_ctx) {
                PlayerContext *ctx = (PlayerContext *)as->player_ctx;
                int64_t playback_head = audio_render_get_playback_head(&as->audio_render);
                static int64_t last_playback_head = 0;  // –î–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —Ä–æ—Å—Ç–∞ playbackHead
                
                if (playback_head > last_playback_head) {
                    static int playback_head_updates = 0;
                    playback_head_updates++;
                    
                    // –ü–µ—Ä–µ—Ö–æ–¥ –≤ AUDIO_PLAYING —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ playbackHead —É–≤–µ–ª–∏—á–∏–ª—Å—è ‚â• 2 —Ä–∞–∑–∞
                    if (ctx->audio_state == AUDIO_INITIALIZED && playback_head_updates >= 2) {
                        ctx->audio_state = AUDIO_PLAYING;
                        ALOGI("üéß AudioState: AUDIO_INITIALIZED ‚Üí AUDIO_PLAYING (playbackHead advancing, updates=%d)", playback_head_updates);
                        extern void native_player_emit_audio_state_event(const char *state);
                        native_player_emit_audio_state_event("playing");
                    } else if (ctx->audio_state == AUDIO_STOPPED_BY_SYSTEM && playback_head > last_playback_head) {
                        // –ü–µ—Ä–µ—Ö–æ–¥ stoppedBySystem ‚Üí playing (AudioTrack –≤–æ–∑–æ–±–Ω–æ–≤–∏–ª—Å—è)
                        ctx->audio_state = AUDIO_PLAYING;
                        playback_head_updates = 2;  // –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á—ë—Ç—á–∏–∫
                        ALOGI("üéß AudioState: AUDIO_STOPPED_BY_SYSTEM ‚Üí AUDIO_PLAYING (AudioTrack resumed)");
                        extern void native_player_emit_audio_state_event(const char *state);
                        native_player_emit_audio_state_event("playing");
                    }
                    
                    last_playback_head = playback_head;
                } else if (playback_head == last_playback_head && ctx->audio_state == AUDIO_PLAYING) {
                    // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: AudioState Contract (RFC v1) - —Ç–æ—á–∫–∞ –ø–µ—Ä–µ—Ö–æ–¥–∞ 5Ô∏è‚É£ AUDIO_STOPPED_BY_SYSTEM
                    // playbackHead –∑–∞–º–µ—Ä ‚Üí AudioTrack –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —Å–∏—Å—Ç–µ–º–æ–π
                    static int frozen_count = 0;
                    static int64_t frozen_start_time = 0;
                    int64_t current_time = av_gettime() / 1000; // –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥—ã
                    
                    if (frozen_count == 0) {
                        frozen_start_time = current_time;
                    }
                    frozen_count++;
                    
                    // –ï—Å–ª–∏ playbackHead –∑–∞–º–µ—Ä > 1 —Å–µ–∫—É–Ω–¥—ã ‚Üí AUDIO_STOPPED_BY_SYSTEM
                    if (current_time - frozen_start_time > 1000) {
                        ctx->audio_state = AUDIO_STOPPED_BY_SYSTEM;
                        ALOGW("‚ö†Ô∏è AudioState: AUDIO_PLAYING ‚Üí AUDIO_STOPPED_BY_SYSTEM (playbackHead frozen for %ld ms)", 
                              (long)(current_time - frozen_start_time));
                        
                        // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: AVSYNC-IMPLEMENTATION - Audio exception = –º–≥–Ω–æ–≤–µ–Ω–Ω–∞—è —Å–º–µ—Ä—Ç—å AVSYNC
                        avsync_gate_invalidate(&ctx->avsync_gate, "audio exception: playbackHead frozen");
                        
                        extern void native_player_emit_audio_state_event(const char *state);
                        native_player_emit_audio_state_event("stoppedBySystem");
                        
                        // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: AUDIO CLOCK SOURCE FIX - –∏–Ω–≤–∞–ª–∏–¥–∏—Ä—É–µ–º clock –ø—Ä–∏ AudioTrack exception
                        // –ò–Ω–≤–∞–ª–∏–¥–∏—Ä—É–µ–º audio clock –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ —Å–∏—Å—Ç–µ–º–æ–π
                        as->clock.valid = 0;
                        // –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: AudioClock –Ω–µ –∏–º–µ–µ—Ç –ø–æ–ª—è stalled, –∏—Å–ø–æ–ª—å–∑—É–µ–º valid=0 –¥–ª—è –∏–Ω–¥–∏–∫–∞—Ü–∏–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
                        
                        // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: AVSYNC HARDENING - –ø–æ–º–µ—á–∞–µ–º audio –∫–∞–∫ unhealthy
                        ctx->avsync.audio_healthy = 0;
                        
                        // ‚õî STOP EVERYTHING - —ç–º–∏—Ç–∏–º error —Å–æ–±—ã—Ç–∏–µ
                        extern void native_player_emit_error_event(const char *message);
                        native_player_emit_error_event("AUDIO_MASTER_LOST");
                        
                        // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: AVSYNC-CODE-DIFF - –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º playback –ø—Ä–∏ audio exception
                        extern void player_pause(PlayerContext *ctx);
                        player_pause(ctx);
                        
                        frozen_count = 0; // –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á—ë—Ç—á–∏–∫
                    } else if (frozen_count == 1) {
                        ALOGW("‚ö†Ô∏è AudioState: playbackHead frozen (possible AUDIO_STOPPED_BY_SYSTEM, waiting for timeout)");
                    }
                }
                
                // –û–±–Ω–æ–≤–ª—è–µ–º as->samples_written –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                // –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: samples —É–∂–µ –∑–∞–ø–∏—Å–∞–Ω—ã —á–µ—Ä–µ–∑ audio_render_write, –∏—Å–ø–æ–ª—å–∑—É–µ–º frame->nb_samples
                if (written > 0 && frame) {
                    as->samples_written += frame->nb_samples;
                }
            }
        }
        
        // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: AVSYNC-IMPLEMENTATION - Clock stall detector (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π)
        // –ü—Ä–æ–≤–µ—Ä—è–µ–º stall –∫–∞–∂–¥—ã–µ 500ms (–ø–æ—Å–ª–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è audio clock)
        if (as->player_ctx) {
            PlayerContext *ctx = (PlayerContext *)as->player_ctx;
            static int64_t last_stall_check_us = 0;  // –°—Ç–∞—Ç–∏—á–µ—Å–∫–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø–æ—Å–ª–µ–¥–Ω–µ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
            const int64_t stall_check_interval_us = 500000;  // 500ms –≤ –º–∏–∫—Ä–æ—Å–µ–∫—É–Ω–¥–∞—Ö
            int64_t now_us = av_gettime_relative(); // –ò—Å–ø–æ–ª—å–∑—É–µ–º av_gettime_relative –¥–ª—è –º–∏–∫—Ä–æ—Å–µ–∫—É–Ω–¥
            if (last_stall_check_us == 0 || (now_us - last_stall_check_us >= stall_check_interval_us)) {
                if (avsync_gate_check_stall(&ctx->avsync_gate, 500000)) { // 500ms threshold
                    // Clock stall –æ–±–Ω–∞—Ä—É–∂–µ–Ω ‚Üí –∏–Ω–≤–∞–ª–∏–¥–∏—Ä—É–µ–º AVSYNC –∏ —ç–º–∏—Ç–∏–º error
                    avsync_gate_invalidate(&ctx->avsync_gate, "MASTER CLOCK STALLED");
                    extern void native_player_emit_error_event(const char *message);
                    native_player_emit_error_event("CLOCK_STALL");
                }
                last_stall_check_us = now_us;
            }
        }
        
        av_frame_free(&frame);
    }
    
    return NULL;
}

/// –ü–æ—Ç–æ–∫ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –∞—É–¥–∏–æ
///
/// –î–µ–∫–æ–¥–∏—Ä—É–µ—Ç –ø–∞–∫–µ—Ç—ã –∏–∑ PacketQueue –∏ –ø–æ–º–µ—â–∞–µ—Ç decoded frames –≤ FrameQueue
/// ‚ùå –ù–ï –æ–±–Ω–æ–≤–ª—è–µ—Ç audio_clock (—ç—Ç–æ –¥–µ–ª–∞–µ—Ç —Ç–æ–ª—å–∫–æ render thread)
/// –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç EOF (–®–∞–≥ 22)
static void *audio_decode_thread(void *arg) {
    AudioState *as = (AudioState *)arg;
    AVPacket pkt;
    AVFrame *frame = av_frame_alloc();
    
    // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: SEEK + AVSYNC PATCH - drop until target reached
    PlayerContext *ctx = as->player_ctx;
    uint8_t **resampled_data = NULL;
    int resampled_linesize = 0;
    
    if (!frame) {
        return NULL;
    }
    
    while (!as->abort) {
        // –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–∞–∫–µ—Ç –∏–∑ –æ—á–µ—Ä–µ–¥–∏ (–±–ª–æ–∫–∏—Ä—É—é—â–∏–π)
        int ret = packet_queue_get(as->packetQueue, &pkt, true);
        if (ret <= 0) {
            // EOF –∏–ª–∏ abort (–®–∞–≥ 22)
            // –ü–æ–º–µ—á–∞–µ–º audio –∫–∞–∫ –∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã–π
            if (as->player_ctx) {
                PlayerContext *ctx = (PlayerContext *)as->player_ctx;
                ctx->state.audio_finished = 1;
                // –ü—Ä–æ–≤–µ—Ä—è–µ–º EOF (–µ—Å–ª–∏ –∏ video –∑–∞–≤–µ—Ä—à–∏–ª—Å—è)
                handle_eof(ctx);
            }
            break;
        }
        
        // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: SEEK + AVSYNC PATCH - –®–ê–ì 10.4: –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å—Ç–∞—Ä—ã—Ö —ç–ø–æ—Ö
        // –ï—Å–ª–∏ –ø–∞–∫–µ—Ç –∏–∑ —Å—Ç–∞—Ä–æ–π —ç–ø–æ—Ö–∏ (serial –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç), –¥—Ä–æ–ø–∞–µ–º –µ–≥–æ
        // –≠—Ç–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ä—ã—Ö –ø–∞–∫–µ—Ç–æ–≤ –ø–æ—Å–ª–µ seek
        if (ctx) {
            int current_serial = atomic_load(&ctx->seek_serial);
            // –ü–∞–∫–µ—Ç—ã –Ω–µ –∏–º–µ—é—Ç serial, –Ω–æ –º—ã –ø—Ä–æ–≤–µ—Ä—è–µ–º seek.in_progress
            // –ï—Å–ª–∏ seek –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ, –¥—Ä–æ–ø–∞–µ–º –ø–∞–∫–µ—Ç—ã –¥–æ —Ç–µ—Ö –ø–æ—Ä, –ø–æ–∫–∞ –Ω–µ –Ω–∞–π–¥—ë–º –ø–µ—Ä–≤—ã–π >= target
            if (ctx->seek.in_progress && ctx->seek.drop_audio) {
                av_packet_unref(&pkt);
                continue;  // –î—Ä–æ–ø–∞–µ–º –ø–∞–∫–µ—Ç –∏–∑ —Å—Ç–∞—Ä–æ–π —ç–ø–æ—Ö–∏
            }
        }
        
        // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–∞–∫–µ—Ç –≤ –¥–µ–∫–æ–¥–µ—Ä
        if (avcodec_send_packet(as->codecCtx, &pkt) < 0) {
            av_packet_unref(&pkt);
            continue;
        }
        
        av_packet_unref(&pkt);
        
        // –ü–æ–ª—É—á–∞–µ–º –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–∞–¥—Ä—ã
        while (!as->abort) {
            int ret = avcodec_receive_frame(as->codecCtx, frame);
            
            if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF) {
                break;
            }
            
            if (ret < 0) {
                goto end;
            }
            
            // üîÑ Resample
            // –í—ã—á–∏—Å–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã—Ö–æ–¥–Ω—ã—Ö —Å—ç–º–ø–ª–æ–≤
            int out_samples = av_rescale_rnd(
                swr_get_delay(as->swr, as->codecCtx->sample_rate) + frame->nb_samples,
                as->codecCtx->sample_rate,
                as->codecCtx->sample_rate,
                AV_ROUND_UP
            );
            
            // –í—ã–¥–µ–ª—è–µ–º –ø–∞–º—è—Ç—å –¥–ª—è —Ä–µ—Å–µ–º–ø–ª–∏–Ω–≥–∞
            av_samples_alloc_array_and_samples(
                &resampled_data,
                &resampled_linesize,
                2, // stereo
                out_samples,
                AV_SAMPLE_FMT_S16,
                0
            );
            
            if (!resampled_data) {
                goto end;
            }
            
            // –í—ã–ø–æ–ª–Ω—è–µ–º —Ä–µ—Å–µ–º–ø–ª–∏–Ω–≥
            int samples = swr_convert(
                as->swr,
                resampled_data,
                out_samples,
                (const uint8_t **)frame->data,
                frame->nb_samples
            );
            
            if (samples < 0) {
                av_freep(&resampled_data[0]);
                av_freep(&resampled_data);
                continue;
            }
            
            // üéØ –ü—Ä–∏–º–µ–Ω—è–µ–º drift correction (–®–∞–≥ 7)
            // –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—ç–º–ø–ª–æ–≤ –¥–ª—è –∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏–∏ –¥—Ä–µ–π—Ñ–∞
            int corrected_samples = audio_drift_correction_apply(as, samples);
            
            // –ï—Å–ª–∏ –∫–æ—Ä—Ä–µ–∫—Ü–∏—è –∏–∑–º–µ–Ω–∏–ª–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—ç–º–ø–ª–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
            if (corrected_samples != samples) {
                samples = corrected_samples;
            }
            
            // ‚ùå –ù–ï –æ–±–Ω–æ–≤–ª—è–µ–º audio_clock –∑–¥–µ—Å—å
            // audio_clock –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è –¢–û–õ–¨–ö–û –≤ audio_render_thread –Ω–∞ –æ—Å–Ω–æ–≤–µ samples_written
            
            // üß± Push PCM frame –≤ –æ—á–µ—Ä–µ–¥—å (–Ω–æ–≤—ã–π API)
            // –°–æ–∑–¥–∞—ë–º –≤—ã—Ö–æ–¥–Ω–æ–π –∫–∞–¥—Ä
            AVFrame *out = av_frame_alloc();
            if (!out) {
                av_freep(&resampled_data[0]);
                av_freep(&resampled_data);
                continue;
            }
            
            out->format = AV_SAMPLE_FMT_S16;
            out->channel_layout = AV_CH_LAYOUT_STEREO;
            out->sample_rate = as->codecCtx->sample_rate;
            out->nb_samples = samples;
            
            if (av_frame_get_buffer(out, 0) < 0) {
                av_frame_free(&out);
                av_freep(&resampled_data[0]);
                av_freep(&resampled_data);
                continue;
            }
            
            // –ö–æ–ø–∏—Ä—É–µ–º —Ä–µ—Å–µ–º–ø–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            memcpy(out->data[0], resampled_data[0], samples * 2 * 2); // stereo, 16-bit
            
            // –í—ã—á–∏—Å–ª—è–µ–º PTS
            int64_t frame_pts = frame->pts;
            double pts = frame_pts == AV_NOPTS_VALUE
                ? NAN
                : frame_pts * av_q2d(as->codecCtx->time_base);
            
            // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: AUDIO CLOCK SOURCE FIX - —Å–æ—Ö—Ä–∞–Ω—è–µ–º last_written_pts
            // PTS is source of truth - —Å–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è clock –ø—Ä–∏ write
            // ‚ö†Ô∏è –ù–ï –æ–±–Ω–æ–≤–ª—è–µ–º clock –∑–¥–µ—Å—å ‚Äî —Ç–æ–ª—å–∫–æ –∑–∞–ø–æ–º–∏–Ω–∞–µ–º PTS
            // –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: audio_clock –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ as->clock, –Ω–µ –≤ ctx->audio_clock
            if (as->player_ctx && !isnan(pts) && pts >= 0.0) {
                // PTS —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –≤ as->clock.last_pts –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ clock
            }
            
            // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: SEEK + AVSYNC PATCH - –®–ê–ì 6.7
            // üîä AUDIO: –ù–ò–ö–û–ì–î–ê –ù–ï –î–ê–Å–ú –ó–í–£–ö –î–û VIDEO
            // üëâ Video ‚Äî master –¥–ª—è –≤—ã—Ö–æ–¥–∞ –∏–∑ seek
            if (as->player_ctx) {
                PlayerContext *ctx = (PlayerContext *)as->player_ctx;
                
                if (ctx->seek.in_progress || ctx->seek.drop_audio) {
                    // ‚õîÔ∏è audio silence until video first frame after seek
                    ALOGD("üîç SEEK: dropping audio frame (audio silence until video first frame)");
                    av_frame_free(&out);
                    av_freep(&resampled_data[0]);
                    av_freep(&resampled_data);
                    continue; // DROP
                }
                
                // –ü–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è seek (video –Ω–∞—à—ë–ª –ø–µ—Ä–≤—ã–π –∫–∞–¥—Ä) - —Ä–∞–∑—Ä–µ—à–∞–µ–º audio
                if (!ctx->seek.in_progress && ctx->seek.drop_audio) {
                    ctx->seek.drop_audio = false;
                    ALOGI("‚úÖ SEEK: Audio drop disabled (video first frame found)");
                }
            }
            
            // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: SEEK + AVSYNC PATCH - –®–ê–ì 10.5: –ü–µ—Ä–µ–¥–∞—ë–º serial —ç–ø–æ—Ö–∏
            // –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–π seek_serial –∏–∑ PlayerContext
            int current_serial = 0;
            if (ctx) {
                current_serial = atomic_load(&ctx->seek_serial);
            }
            
            // –î–æ–±–∞–≤–ª—è–µ–º –∫–∞–¥—Ä –≤ –æ—á–µ—Ä–µ–¥—å (–∫–ª–æ–Ω–∏—Ä—É–µ—Ç—Å—è –≤–Ω—É—Ç—Ä–∏) —Å serial —ç–ø–æ—Ö–∏
            if (frame_queue_push(as->frameQueue, out, pts, current_serial) < 0) {
                av_frame_free(&out);
                av_freep(&resampled_data[0]);
                av_freep(&resampled_data);
                continue;
            }
            
            // –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π –∫–∞–¥—Ä (–æ–Ω –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω –≤ –æ—á–µ—Ä–µ–¥–∏)
            av_frame_free(&out);
            av_freep(&resampled_data[0]);
            av_freep(&resampled_data);
        }
    }
    
end:
    av_frame_free(&frame);
    if (resampled_data) {
        av_freep(&resampled_data[0]);
        av_freep(&resampled_data);
    }
    return NULL;
}

int audio_decoder_init(AudioState *as, AVStream *stream) {
    if (!as || !stream) {
        ALOGE("‚ùå audio_decoder_init: Invalid parameters");
        return -1;
    }
    
    // üî¥ –®–ê–ì 2: –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø AUDIO DECODER (–≠–¢–ê–õ–û–ù)
    // –ù–∞—Ö–æ–¥–∏–º –¥–µ–∫–æ–¥–µ—Ä
    const AVCodec *codec = avcodec_find_decoder(stream->codecpar->codec_id);
    if (!codec) {
        ALOGE("‚ùå audio_decoder_init: Codec not found (codec_id=%d)", stream->codecpar->codec_id);
        return -1;
    }
    
    ALOGI("üîä Audio decoder found: %s", codec->name);
    
    // –í—ã–¥–µ–ª—è–µ–º codec context
    as->codecCtx = avcodec_alloc_context3(codec);
    if (!as->codecCtx) {
        ALOGE("‚ùå audio_decoder_init: Failed to allocate codec context");
        return -1;
    }
    
    // –ö–æ–ø–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ —Å—Ç—Ä–∏–º–∞
    if (avcodec_parameters_to_context(as->codecCtx, stream->codecpar) < 0) {
        ALOGE("‚ùå audio_decoder_init: Failed to copy codec parameters");
        avcodec_free_context(&as->codecCtx);
        return -1;
    }
    
    // –û—Ç–∫—Ä—ã–≤–∞–µ–º –¥–µ–∫–æ–¥–µ—Ä
    if (avcodec_open2(as->codecCtx, codec, NULL) < 0) {
        ALOGE("‚ùå audio_decoder_init: Failed to open audio decoder");
        avcodec_free_context(&as->codecCtx);
        return -1;
    }
    
    ALOGI("‚úÖ Audio decoder opened: sample_rate=%d, channels=%d, format=%d",
          as->codecCtx->sample_rate,
          #if LIBAVCODEC_VERSION_MAJOR >= 60
          as->codecCtx->ch_layout.nb_channels,
          #else
          as->codecCtx->channels,
          #endif
          as->codecCtx->sample_fmt);
    
    // –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    as->sample_rate = as->codecCtx->sample_rate;
    
    // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: AUDIO CLOCK SOURCE FIX - –®–ê–ì 7
    // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è AudioClock —Å—Ç—Ä—É–∫—Ç—É—Ä—ã (PTS-based)
    memset(&as->clock, 0, sizeof(AudioClock));
    as->clock.clock = NAN;
    as->clock.last_pts = NAN;
    as->clock.last_duration = 0.0;
    as->clock.latency = 0.0;
    as->clock.last_update_us = 0;
    as->clock.valid = 0;
    
    // Legacy –ø–æ–ª—è (deprecated)
    as->audio_clock_pts = NAN;
    as->last_audio_clock_pts = NAN;
    
    // –î–ª—è FFmpeg 6.0+ –∏—Å–ø–æ–ª—å–∑—É–µ–º ch_layout, –¥–ª—è —Å—Ç–∞—Ä—ã—Ö –≤–µ—Ä—Å–∏–π - channels
    #if LIBAVCODEC_VERSION_MAJOR >= 60
        as->channels = as->codecCtx->ch_layout.nb_channels;
    #else
        as->channels = as->codecCtx->channels;
    #endif
    as->sample_fmt = AV_SAMPLE_FMT_S16; // AudioTrack –ª—é–±–∏—Ç S16
    
    // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º audio clock –∏ samples_written (–®–∞–≥ 11)
    as->audio_clock = 0.0;
    as->audio_pts_start = 0.0;
    as->samples_written = 0;
    as->playback_head_samples = 0;
    as->abort = 0;
    as->paused = 0;
    as->out_buf = NULL;
    as->out_buf_size = 0;
    as->jvm = NULL;
    
    // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º clock (–®–∞–≥ 20)
    clock_init(&as->clock);
    
    // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º drift correction
    audio_drift_correction_init(as);
    
    // audio_render –±—É–¥–µ—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –≤ audio_threads_start
    
    ALOGI("‚úÖ audio_decoder_init: Audio decoder initialized successfully");
    return 0;
}

int audio_swr_init(AudioState *as) {
    if (!as || !as->codecCtx) {
        ALOGE("‚ùå audio_swr_init: Invalid parameters");
        return -1;
    }
    
    AVCodecContext *c = as->codecCtx;
    
    // üî¥ –®–ê–ì 5: SWR ‚Üí PCM (–ï–°–õ–ò –ù–ï PCM) (–≠–¢–ê–õ–û–ù)
    // –í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º swr, –¥–∞–∂–µ –µ—Å–ª–∏ —Ñ–æ—Ä–º–∞—Ç "—Å–æ–≤–ø–∞–¥–∞–µ—Ç"
    // (–∏–Ω–∞—á–µ —Å–ª–æ–º–∞–µ—Ç—Å—è –Ω–∞ –¥—Ä—É–≥–æ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ)
    // –ò—Å–ø–æ–ª—å–∑—É–µ–º swr_alloc_set_opts –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
    // Output: stereo, S16
    uint64_t out_ch_layout = AV_CH_LAYOUT_STEREO;
    
    // Input: –∏—Å–ø–æ–ª—å–∑—É–µ–º channel_layout –∏–∑ codec context
    // –î–ª—è FFmpeg 6.0+ –∏—Å–ø–æ–ª—å–∑—É–µ–º ch_layout, –¥–ª—è —Å—Ç–∞—Ä—ã—Ö –≤–µ—Ä—Å–∏–π - channel_layout
    uint64_t in_ch_layout;
    #if LIBAVCODEC_VERSION_MAJOR >= 60
        in_ch_layout = c->ch_layout.u.mask;
    #else
        in_ch_layout = c->channel_layout;
    #endif
    
    ALOGI("üîä SWR init: in_ch_layout=%llu, in_fmt=%d, in_rate=%d ‚Üí out_ch_layout=%llu, out_fmt=%d, out_rate=%d",
          (unsigned long long)in_ch_layout, c->sample_fmt, c->sample_rate,
          (unsigned long long)out_ch_layout, as->sample_fmt, as->sample_rate);
    
    as->swr = swr_alloc_set_opts(
        NULL,
        out_ch_layout,            // output: stereo
        as->sample_fmt,           // output: S16
        as->sample_rate,          // output: same sample rate
        in_ch_layout,             // input: original channel layout
        c->sample_fmt,            // input: original sample format
        c->sample_rate,           // input: original sample rate
        0,                        // log offset
        NULL                      // log context
    );
    
    if (!as->swr) {
        ALOGE("‚ùå audio_swr_init: Failed to allocate SWR context");
        return -1;
    }
    
    if (swr_init(as->swr) < 0) {
        ALOGE("‚ùå audio_swr_init: Failed to initialize SWR context");
        swr_free(&as->swr);
        return -1;
    }
    
    ALOGI("‚úÖ SWR initialized successfully");
    
    // –í—ã–¥–µ–ª—è–µ–º –±—É—Ñ–µ—Ä –¥–ª—è —Ä–µ—Å–µ–º–ø–ª–∏–Ω–≥–∞
    as->out_buf_size = av_samples_get_buffer_size(
        NULL,
        as->channels,
        c->frame_size > 0 ? c->frame_size : 4096,
        as->sample_fmt,
        0
    );
    
    if (as->out_buf_size < 0) {
        swr_free(&as->swr);
        return -1;
    }
    
    as->out_buf = (uint8_t *)av_malloc(as->out_buf_size);
    if (!as->out_buf) {
        swr_free(&as->swr);
        return -1;
    }
    
    return 0;
}

int audio_threads_start(AudioState *as, JavaVM *jvm) {
    if (!as || !jvm) {
        ALOGE("‚ùå audio_threads_start: Invalid parameters");
        return -1;
    }
    
    as->jvm = jvm;
    as->abort = 0;
    
    // üî¥ –®–ê–ì 6: ANDROID AudioTrack (–≠–¢–ê–õ–û–ù)
    // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º AudioTrack
    ALOGI("üîä Initializing AudioTrack: sample_rate=%d, channels=%d", as->sample_rate, as->channels);
    if (!audio_render_init(&as->audio_render, jvm, as->sample_rate, as->channels)) {
        ALOGE("‚ùå audio_threads_start: Failed to initialize AudioTrack");
        return -1;
    }
    
    // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: AUDIO CLOCK SOURCE FIX - –®–ê–ì 16: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è AudioClock
    audio_clock_init(&as->clock);
    
    // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: AUDIO CLOCK SOURCE FIX - –®–ê–ì 16.3: AUDIO LATENCY
    // –í—ã—á–∏—Å–ª—è–µ–º latency –æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
    // latency = audio_buffer_size / (sample_rate * channels * bytes_per_sample)
    // –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º AudioTrack.getLatency() –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
    int latency_ms = audio_render_get_latency(&as->audio_render);
    if (latency_ms > 0) {
        as->clock.latency = latency_ms / 1000.0;  // ms ‚Üí seconds
        ALOGI("üîä AudioClock: Latency initialized: %.3f sec (%d ms)", as->clock.latency, latency_ms);
    } else {
        // Fallback: –≤—ã—á–∏—Å–ª—è–µ–º latency –∏–∑ buffer size
        // AudioTrack buffer size –æ–±—ã—á–Ω–æ ~100-200ms
        // –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—É—é –æ—Ü–µ–Ω–∫—É 100ms
        as->clock.latency = 0.1;  // 100ms fallback
        ALOGW("‚ö†Ô∏è AudioClock: Latency not available, using fallback: %.3f sec", as->clock.latency);
    }
    
    // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: AUDIO-NATIVE Contract - –ø–µ—Ä–µ–¥–∞—ë–º PlayerContext –≤ AudioRenderAndroid
    // –≠—Ç–æ –Ω—É–∂–Ω–æ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è audio_state –ø—Ä–∏ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–∏ PLAYSTATE_PLAYING
    if (as->player_ctx) {
        as->audio_render.player_ctx = as->player_ctx;
    }
    
    // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: MUTE-AUDIO ASSERT - –ø—Ä–æ–≤–µ—Ä—è–µ–º –≥—Ä–æ–º–∫–æ—Å—Ç—å –ø–µ—Ä–µ–¥ AudioTrack.play()
    // –ï—Å–ª–∏ –≥—Ä–æ–º–∫–æ—Å—Ç—å = 0%, AudioTrack –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —Å–∏—Å—Ç–µ–º–æ–π (onAudioException)
    // –≠—Ç–æ –Ω–µ –æ—à–∏–±–∫–∞, –Ω–æ –≤–∞–∂–Ω–æ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ silent playback
    // –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è —á–µ—Ä–µ–∑ JNI (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ) –∏–ª–∏ —Ç–æ–ª—å–∫–æ –ª–æ–≥–∏—Ä—É–µ—Ç—Å—è
    ALOGI("üîä MUTE-AUDIO ASSERT: Checking system volume before AudioTrack.play()");
    ALOGI("   If volume = 0%%, AudioTrack may be stopped by Android AudioSystem");
    ALOGI("   This is expected behavior on some OEM devices (Huawei/HiSilicon)");
    
    // –ó–∞–ø—É—Å–∫–∞–µ–º AudioTrack
    audio_render_start(&as->audio_render);
    ALOGI("‚úÖ AudioTrack started");
    
    // üî¥ –®–ê–ì 4: AUDIO DECODE THREAD (–≠–¢–ê–õ–û–ù)
    // –ó–∞–ø—É—Å–∫–∞–µ–º decode thread
    ALOGI("üîä Starting audio decode thread...");
    if (pthread_create(&as->decodeThread, NULL, audio_decode_thread, as) != 0) {
        ALOGE("‚ùå audio_threads_start: Failed to create audio decode thread");
        audio_render_release(&as->audio_render);
        return -1;
    }
    
    // üî¥ –ö–†–ò–¢–ò–ß–ù–û: –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–ª–∞–≥–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è thread
    as->decodeThread_started = 1;
    as->decodeThread_joined = 0;
    ALOGI("‚úÖ Audio decode thread started");
    
    // –ó–∞–ø—É—Å–∫–∞–µ–º render thread
    ALOGI("üîä Starting audio render thread...");
    if (pthread_create(&as->renderThread, NULL, audio_render_thread, as) != 0) {
        ALOGE("‚ùå audio_threads_start: Failed to create audio render thread");
        as->abort = 1;
        if (as->packetQueue) {
            packet_queue_abort(as->packetQueue);
        }
        // üî¥ –ö–†–ò–¢–ò–ß–ù–û: Join decode thread —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω –±—ã–ª –∑–∞–ø—É—â–µ–Ω
        if (as->decodeThread_started && !as->decodeThread_joined && as->decodeThread) {
            pthread_join(as->decodeThread, NULL);
            as->decodeThread_joined = 1;
            as->decodeThread = 0;
        }
        audio_render_release(&as->audio_render);
        return -1;
    }
    
    // üî¥ –ö–†–ò–¢–ò–ß–ù–û: –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–ª–∞–≥–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è render thread
    as->renderThread_started = 1;
    as->renderThread_joined = 0;
    
    ALOGI("‚úÖ Audio threads started (decode + render)");
    return 0;
}

void audio_threads_stop(AudioState *as) {
    if (!as) {
        return;
    }
    
    // üî¥ –ö–†–ò–¢–ò–ß–ù–û: –ó–∞—â–∏—Ç–∞ –æ—Ç –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –≤—ã–∑–æ–≤–∞
    // –ï—Å–ª–∏ threads —É–∂–µ –±—ã–ª–∏ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã, –Ω–µ –¥–µ–ª–∞–µ–º –Ω–∏—á–µ–≥–æ
    if (as->threads_stopped) {
        ALOGD("‚ö†Ô∏è audio_threads_stop: Already called for this AudioState, skipping");
        return;
    }
    
    as->abort = 1;
    
    // –ü—Ä–µ—Ä—ã–≤–∞–µ–º –æ—á–µ—Ä–µ–¥–∏
    if (as->packetQueue) {
        packet_queue_abort(as->packetQueue);
    }
    if (as->frameQueue) {
        frame_queue_abort(as->frameQueue);
    }
    
    // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º AudioTrack
    audio_render_stop(&as->audio_render);
    
    // üî¥ –ö–†–ò–¢–ò–ß–ù–û: –ñ–¥—ë–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ø–æ—Ç–æ–∫–æ–≤ –¢–û–õ–¨–ö–û –µ—Å–ª–∏ –æ–Ω–∏ –±—ã–ª–∏ –∑–∞–ø—É—â–µ–Ω—ã –∏ –µ—â—ë –Ω–µ join'–Ω—É—Ç—ã
    // –ó–û–õ–û–¢–û–ï –ü–†–ê–í–ò–õ–û: pthread_join –º–æ–∂–Ω–æ –≤—ã–∑—ã–≤–∞—Ç—å –¢–û–õ–¨–ö–û –µ—Å–ª–∏:
    // - thread –±—ã–ª —Å–æ–∑–¥–∞–Ω (decodeThread_started == 1)
    // - thread –µ—â—ë –ù–ï –±—ã–ª joined (decodeThread_joined == 0)
    // - thread != 0 (–≤–∞–ª–∏–¥–Ω—ã–π pthread_t)
    // - join –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –û–î–ò–ù —Ä–∞–∑
    ALOGI("üîÑ audio_threads_stop: decode valid=%d joined=%d tid=%p",
          as->decodeThread_started, as->decodeThread_joined, (void *)as->decodeThread);
    
    if (as->decodeThread_started && !as->decodeThread_joined && as->decodeThread != 0) {
        ALOGI("üîÑ audio_threads_stop: Joining decode thread (thread=%p)", (void *)as->decodeThread);
        pthread_join(as->decodeThread, NULL);
        as->decodeThread_joined = 1;
        as->decodeThread = 0;
        ALOGI("‚úÖ audio_threads_stop: Decode thread joined");
    } else {
        ALOGD("‚ö†Ô∏è audio_threads_stop: Decode thread skip join (started=%d, joined=%d, thread=%p)",
              as->decodeThread_started, as->decodeThread_joined, (void *)as->decodeThread);
    }
    
    ALOGI("üîÑ audio_threads_stop: render valid=%d joined=%d tid=%p",
          as->renderThread_started, as->renderThread_joined, (void *)as->renderThread);
    
    if (as->renderThread_started && !as->renderThread_joined && as->renderThread != 0) {
        ALOGI("üîÑ audio_threads_stop: Joining render thread (thread=%p)", (void *)as->renderThread);
        pthread_join(as->renderThread, NULL);
        as->renderThread_joined = 1;
        as->renderThread = 0;
        ALOGI("‚úÖ audio_threads_stop: Render thread joined");
    } else {
        ALOGD("‚ö†Ô∏è audio_threads_stop: Render thread skip join (started=%d, joined=%d, thread=%p)",
              as->renderThread_started, as->renderThread_joined, (void *)as->renderThread);
    }
    
    // –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º AudioTrack
    audio_render_release(&as->audio_render);
    
    // üî¥ –ö–†–ò–¢–ò–ß–ù–û: –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–ª–∞–≥, —á—Ç–æ threads –±—ã–ª–∏ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã
    as->threads_stopped = 1;
    ALOGI("‚úÖ Audio threads stopped");
}

void audio_decoder_destroy(AudioState *as) {
    if (!as) {
        return;
    }
    
    // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–æ—Ç–æ–∫–∏ (–æ—Å–≤–æ–±–æ–∂–¥–∞–µ—Ç AudioTrack –≤–Ω—É—Ç—Ä–∏ —á–µ—Ä–µ–∑ audio_render_release)
    audio_threads_stop(as);
    
    // –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º –±—É—Ñ–µ—Ä
    if (as->out_buf) {
        av_freep(&as->out_buf);
    }
    
    // –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º swr
    if (as->swr) {
        swr_free(&as->swr);
    }
    
    // –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º codec context
    if (as->codecCtx) {
        avcodec_free_context(&as->codecCtx);
    }
    
    memset(as, 0, sizeof(AudioState));
}

/// üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: AUDIO CLOCK SOURCE FIX - –®–ê–ì 16.4: EXTRAPOLATION
/// ‚õî –ó–ê–ü–†–ï–©–ê–ï–ú playbackHead –∫–∞–∫ –∏—Å—Ç–æ—á–Ω–∏–∫
/// 
/// @param as –°–æ—Å—Ç–æ—è–Ω–∏–µ –∞—É–¥–∏–æ
/// @return –¢–µ–∫—É—â–∏–π audio clock –≤ —Å–µ–∫—É–Ω–¥–∞—Ö (PTS-based —Å extrapolation)
///
/// –ï—Å–ª–∏ –Ω–µ—Ç –Ω–æ–≤—ã—Ö —Ñ—Ä–µ–π–º–æ–≤, —ç–∫—Å—Ç—Ä–∞–ø–æ–ª–∏—Ä—É–µ–º –Ω–∞ –æ—Å–Ω–æ–≤–µ elapsed time
/// –¢–û–õ–¨–ö–û –µ—Å–ª–∏ playing (–Ω–µ paused, –Ω–µ stalled)
/// üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: AVSYNC CODE DIFF - –®–ê–ì 20.1: audio_clock_now()
/// Audio clock = AudioTrack.getPlaybackHeadPosition()
/// ‚ùå PTS –±–æ–ª—å—à–µ –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–∞–∫ master clock
static double audio_clock_now(AudioState *as) {
    if (!as || !as->audio_render.audio_track || !as->audio_render.started) {
        return NAN;
    }
    
    // üî• –®–ê–ì 20.1: –ò—Å–ø–æ–ª—å–∑—É–µ–º AudioTrack.getPlaybackHeadPosition()
    extern int64_t audio_render_get_playback_head(AudioRenderAndroid *ar);
    uint32_t frames = (uint32_t)audio_render_get_playback_head(&as->audio_render);
    
    if (frames == 0 && as->audio_render.started) {
        // AudioTrack –º–æ–∂–µ—Ç –≤–µ—Ä–Ω—É—Ç—å 0 –µ—Å–ª–∏ —Ç–æ–ª—å–∫–æ —á—Ç–æ –∑–∞–ø—É—â–µ–Ω –∏–ª–∏ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
        // –ü—Ä–æ–≤–µ—Ä—è–µ–º play state
        extern int audio_render_get_play_state(AudioRenderAndroid *ar);
        int play_state = audio_render_get_play_state(&as->audio_render);
        if (play_state != 3) {  // PLAYSTATE_PLAYING = 3
            return NAN;  // AudioTrack –Ω–µ –∏–≥—Ä–∞–µ—Ç
        }
    }
    
    // –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º frames –≤ —Å–µ–∫—É–Ω–¥—ã
    double clock_sec = frames / (double)as->sample_rate;
    
    return clock_sec;
}

double audio_get_clock(AudioState *as) {
    if (!as) {
        return NAN;
    }
    
    // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: AVSYNC CODE DIFF - –®–ê–ì 20.1: Audio clock = AudioTrack.getPlaybackHeadPosition()
    // ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º playbackHead –∫–∞–∫ –∏—Å—Ç–æ—á–Ω–∏–∫ –ø—Ä–∞–≤–¥—ã
    // ‚ùå PTS –±–æ–ª—å—à–µ –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–∞–∫ master clock
    double clock_sec = audio_clock_now(as);
    
    // –û–±–Ω–æ–≤–ª—è–µ–º last_clock_update –¥–ª—è stall detection
    if (!isnan(clock_sec)) {
        as->clock.clock = clock_sec;
        as->clock.valid = 1;
        as->clock.last_update_us = av_gettime_relative();
    } else {
        // AudioTrack –Ω–µ –∏–≥—Ä–∞–µ—Ç –∏–ª–∏ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
        as->clock.valid = 0;
    }
    
    return clock_sec;
}

// –°—Ç–∞—Ä—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ —É–¥–∞–ª–µ–Ω—ã - —Ç–µ–ø–µ—Ä—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è audio_render_android

/// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å AudioClock
void audio_clock_init(AudioClock *c) {
    if (!c) {
        return;
    }
    
    c->clock = NAN;
    c->last_pts = NAN;
    c->last_duration = 0.0;
    c->latency = 0.0;
    c->last_update_us = 0;
    c->valid = 0;
    // –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: AudioClock –Ω–µ –∏–º–µ–µ—Ç –ø–æ–ª—è stalled, –∏—Å–ø–æ–ª—å–∑—É–µ–º valid=0 –¥–ª—è –∏–Ω–¥–∏–∫–∞—Ü–∏–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
}

/// –°–±—Ä–æ—Å–∏—Ç—å AudioClock (–ø—Ä–∏ seek)
void audio_clock_reset(AudioClock *c) {
    if (!c) {
        return;
    }
    
    // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: AUDIO CLOCK SOURCE FIX - –®–ê–ì 16.6: SEEK FIX
    // –ü—Ä–∏ seek –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û:
    // c->clock = NAN;
    // c->last_pts = NAN;
    // c->last_update_us = 0;
    // ‚ùå audio clock –Ω–µ –¥–æ–ª–∂–µ–Ω –∂–∏—Ç—å –º–µ–∂–¥—É seek
    c->clock = NAN;
    c->last_pts = NAN;
    c->last_duration = 0.0;
    c->last_update_us = 0;
    c->valid = 0;  // –ò–Ω–≤–∞–ª–∏–¥–∏—Ä—É–µ–º –¥–æ –ø–µ—Ä–≤–æ–≥–æ update –ø–æ—Å–ª–µ seek
    // –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: AudioClock –Ω–µ –∏–º–µ–µ—Ç –ø–æ–ª—è stalled, –∏—Å–ø–æ–ª—å–∑—É–µ–º valid=0 –¥–ª—è –∏–Ω–¥–∏–∫–∞—Ü–∏–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
}

// Legacy —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
void audio_clock_reset_legacy(AudioState *as, double seek_pos) {
    if (!as) {
        return;
    }
    
    // üî¥ –®–ê–ì K.4: Flush AudioTrack –ø—Ä–∏ seek (–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û)
    // ‚õî –ë–ï–ó –≠–¢–û–ì–û –∞—É–¥–∏–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç —Å—Ç–∞—Ä–æ–µ –≤—Ä–µ–º—è –ø–æ—Å–ª–µ seek
    audio_render_flush(&as->audio_render);
    ALOGI("üîç SEEK: AudioTrack flushed");
    
    // –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—É—é —Ñ—É–Ω–∫—Ü–∏—é
    audio_clock_reset(&as->clock);
    
    // –û–±–Ω–æ–≤–ª—è–µ–º PlayerContext->avsync.audio_clock
    if (as->player_ctx) {
        PlayerContext *ctx = (PlayerContext *)as->player_ctx;
        ctx->avsync.audio_clock = seek_pos;  // –í—Ä–µ–º–µ–Ω–Ω–æ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –Ω–∞ seek_pos
        ctx->avsync.audio_healthy = 0;  // –ò–Ω–≤–∞–ª–∏–¥–∏—Ä—É–µ–º –¥–æ –ø–µ—Ä–≤–æ–≥–æ update
        ctx->avsync.last_audio_clock = seek_pos;
        ctx->avsync.last_audio_clock_ts = 0;
        ALOGI("üîç SEEK: audio_clock reset to NAN (will be updated from PTS after seek)");
    }
    
    // Legacy –ø–æ–ª—è (–¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
    as->clock_valid = 0;
    as->track_failed = 0;
    as->clock_base_pts = 0.0;
    as->clock_base_time_sec = 0.0;
    as->audio_clock_pts = NAN;
    as->last_audio_clock_pts = NAN;
    
    // Legacy audio_clock (deprecated)
    as->audio_clock = seek_pos;
    
    // –°–±—Ä–∞—Å—ã–≤–∞–µ–º clock –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ (–®–∞–≥ 20)
    clock_reset(&as->clock, seek_pos);
    
    // –°–±—Ä–∞—Å—ã–≤–∞–µ–º drift correction
    audio_drift_correction_reset(as);
    
    // –°–±—Ä–∞—Å—ã–≤–∞–µ–º samples_written –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –ø–µ—Ä–µ—Å—á—ë—Ç–∞
    as->samples_written = 0;
    as->playback_head_samples = 0;
    
    ALOGI("üîç SEEK: audio_clock reset (seek mode)");
}

void audio_pause(AudioState *as) {
    if (!as) {
        return;
    }
    
    audio_render_pause(&as->audio_render);
    
    // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: AudioState Contract (RFC v1) - —Ç–æ—á–∫–∞ –ø–µ—Ä–µ—Ö–æ–¥–∞ 7Ô∏è‚É£ AUDIO_PAUSED
    // App pause ‚Üí AUDIO_PAUSED
    if (as->player_ctx) {
        PlayerContext *ctx = (PlayerContext *)as->player_ctx;
        if (ctx->audio_state == AUDIO_PLAYING) {
            ctx->audio_state = AUDIO_PAUSED;
            ALOGI("üéß AudioState: AUDIO_PLAYING ‚Üí AUDIO_PAUSED (app pause)");
            extern void native_player_emit_audio_state_event(const char *state);
            native_player_emit_audio_state_event("paused");
        }
    }
}

void audio_resume(AudioState *as) {
    if (!as) {
        return;
    }
    
    audio_render_start(&as->audio_render);
    
    // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: AudioState Contract (RFC v1) - —Ç–æ—á–∫–∞ –ø–µ—Ä–µ—Ö–æ–¥–∞ AUDIO_PAUSED ‚Üí AUDIO_PLAYING
    // App resume ‚Üí AUDIO_PLAYING (–±—É–¥–µ—Ç –ø–æ–¥—Ç–≤–µ—Ä–∂–¥—ë–Ω –ø—Ä–∏ —Ä–æ—Å—Ç–µ playbackHead)
    if (as->player_ctx) {
        PlayerContext *ctx = (PlayerContext *)as->player_ctx;
        if (ctx->audio_state == AUDIO_PAUSED) {
            // –ü–µ—Ä–µ—Ö–æ–¥ –≤ AUDIO_INITIALIZED, –∑–∞—Ç–µ–º –≤ AUDIO_PLAYING –ø—Ä–∏ —Ä–æ—Å—Ç–µ playbackHead
            ctx->audio_state = AUDIO_INITIALIZED;
            ALOGI("üéß AudioState: AUDIO_PAUSED ‚Üí AUDIO_INITIALIZED (app resume, waiting for playbackHead)");
        }
    }
}

bool audio_queue_empty(AudioState *as) {
    if (!as || !as->frameQueue) {
        return true;
    }
    
    // TODO: –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–∞–∑–º–µ—Ä –æ—á–µ—Ä–µ–¥–∏ —á–µ—Ä–µ–∑ frame_queue_size()
    // –ü–æ–∫–∞ –∑–∞–≥–ª—É—à–∫–∞
    return false;
}

// === Audio Latency & Drift Correction (–®–ê–ì 5) ===

#define AUDIO_DIFF_AVG_NB 20
#define AV_SYNC_THRESHOLD 0.04   // 40 ms (–®–ê–ì 5.4)
#define AV_NO_SYNC_THRESHOLD 0.1 // 100 ms (–®–ê–ì 5.4)
#define MAX_CORRECTION_PERCENT 0.005 // ¬±0.5% (–®–ê–ì 5.5)

// –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è clamp
static double clamp_double(double value, double min, double max) {
    if (value < min) return min;
    if (value > max) return max;
    return value;
}

void audio_drift_correction_init(AudioState *as) {
    if (!as) {
        return;
    }
    
    as->audio_diff_avg = 0.0;
    as->audio_diff_cum = 0.0; // –®–ê–ì 5.3: –ù–∞–∫–æ–ø–∏—Ç–µ–ª—å–Ω–∞—è —Å—É–º–º–∞
    as->audio_diff_count = 0;  // –®–ê–ì 5.3: –°—á—ë—Ç—á–∏–∫
    as->audio_diff_avg_coef = 0.95; // –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ
    as->audio_diff_threshold = AV_SYNC_THRESHOLD;
    as->audio_no_sync_threshold = AV_NO_SYNC_THRESHOLD;
    as->wanted_nb_samples = 0;
    as->target_sample_rate = as->sample_rate; // –®–ê–ì 5.5: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∫ sample_rate
    as->audio_latency_ms = 0;
}

int audio_drift_correction_apply(AudioState *as, int nb_samples) {
    if (!as) {
        return nb_samples;
    }
    
    // –®–ê–ì 5.4: –†–µ—à–∞–µ–º, –Ω—É–∂–Ω–∞ –ª–∏ –∫–æ—Ä—Ä–µ–∫—Ü–∏—è
    if (fabs(as->audio_diff_avg) < as->audio_diff_threshold) {
        // –í—Å—ë —Ö–æ—Ä–æ—à–æ - –∫–æ—Ä—Ä–µ–∫—Ü–∏—è –Ω–µ –Ω—É–∂–Ω–∞
        as->wanted_nb_samples = nb_samples;
        as->target_sample_rate = as->sample_rate;
        
        // –°–±—Ä–∞—Å—ã–≤–∞–µ–º compensation –µ—Å–ª–∏ –±—ã–ª —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
        if (as->swr) {
            swr_set_compensation(as->swr, 0, as->sample_rate);
        }
        return nb_samples;
    }
    
    if (fabs(as->audio_diff_avg) >= as->audio_no_sync_threshold) {
        // –î—Ä–µ–π—Ñ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π - –Ω–µ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º (–º–æ–∂–µ—Ç –±—ã—Ç—å seek/pause)
        as->wanted_nb_samples = nb_samples;
        as->target_sample_rate = as->sample_rate;
        return nb_samples;
    }
    
    // –®–ê–ì 5.5: –ú—è–≥–∫–∞—è –∫–æ—Ä—Ä–µ–∫—Ü–∏—è (–º–∞–∫—Å–∏–º—É–º ¬±0.5%)
    double correction = clamp_double(as->audio_diff_avg * 0.1, -MAX_CORRECTION_PERCENT, MAX_CORRECTION_PERCENT);
    as->target_sample_rate = as->sample_rate * (1.0 - correction);
    
    // –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ü–∏—é –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å—ç–º–ø–ª–æ–≤
    // wanted_nb_samples = nb_samples + (int)(diff * sample_rate)
    double correction_samples = as->audio_diff_avg * as->sample_rate;
    as->wanted_nb_samples = nb_samples + (int)correction_samples;
    
    // –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ—Ä—Ä–µ–∫—Ü–∏—é (–Ω–µ –±–æ–ª–µ–µ ¬±0.5%)
    int max_correction = (int)(nb_samples * MAX_CORRECTION_PERCENT);
    if (as->wanted_nb_samples > nb_samples + max_correction) {
        as->wanted_nb_samples = nb_samples + max_correction;
    } else if (as->wanted_nb_samples < nb_samples - max_correction) {
        as->wanted_nb_samples = nb_samples - max_correction;
    }
    
    // –®–ê–ì 5.6: –ü—Ä–∏–º–µ–Ω—è–µ–º time stretch —á–µ—Ä–µ–∑ swr_set_compensation
    // pitch –Ω–µ –º–µ–Ω—è–µ—Ç—Å—è, —Ç–æ–ª—å–∫–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—ç–º–ø–ª–æ–≤
    if (as->swr) {
        int compensation = (int)(as->audio_diff_avg * as->sample_rate);
        swr_set_compensation(as->swr, compensation, as->sample_rate);
    }
    
    return as->wanted_nb_samples;
}

void audio_drift_correction_update(AudioState *as, double drift) {
    if (!as) {
        return;
    }
    
    // –®–ê–ì 5.3: –£—Å—Ä–µ–¥–Ω—è–µ–º diff (anti-jitter)
    // –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–≤–∞ –º–µ—Ç–æ–¥–∞: –Ω–∞–∫–æ–ø–∏—Ç–µ–ª—å–Ω–æ–µ –∏ —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ
    as->audio_diff_cum += drift;
    as->audio_diff_count++;
    
    if (as->audio_diff_count >= AUDIO_DIFF_AVG_NB) {
        // –ù–∞–∫–æ–ø–∏—Ç–µ–ª—å–Ω–æ–µ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ (–®–ê–ì 5.3)
        as->audio_diff_avg = as->audio_diff_cum / as->audio_diff_count;
        as->audio_diff_cum = 0.0;
        as->audio_diff_count = 0;
    } else {
        // –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ (–¥–ª—è –ø–ª–∞–≤–Ω–æ—Å—Ç–∏)
        as->audio_diff_avg = as->audio_diff_avg * as->audio_diff_avg_coef + 
                             drift * (1.0 - as->audio_diff_avg_coef);
    }
    
    // –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –¥—Ä–µ–π—Ñ (¬±100ms)
    if (as->audio_diff_avg > 0.1) {
        as->audio_diff_avg = 0.1;
    } else if (as->audio_diff_avg < -0.1) {
        as->audio_diff_avg = -0.1;
    }
}

void audio_drift_correction_reset(AudioState *as) {
    if (!as) {
        return;
    }
    
    // –°–±—Ä–∞—Å—ã–≤–∞–µ–º –¥—Ä–µ–π—Ñ (–ø—Ä–∏ seek/resume)
    as->audio_diff_avg = 0.0;
    as->audio_diff_cum = 0.0; // –®–ê–ì 5.3: –°–±—Ä–æ—Å –Ω–∞–∫–æ–ø–∏—Ç–µ–ª—å–Ω–æ–π —Å—É–º–º—ã
    as->audio_diff_count = 0;  // –®–ê–ì 5.3: –°–±—Ä–æ—Å —Å—á—ë—Ç—á–∏–∫–∞
    as->wanted_nb_samples = 0;
    as->target_sample_rate = as->sample_rate; // –®–ê–ì 5.5: –°–±—Ä–æ—Å target rate
    
    // –°–±—Ä–∞—Å—ã–≤–∞–µ–º compensation –≤ swr
    if (as->swr) {
        swr_set_compensation(as->swr, 0, as->sample_rate);
    }
}

int audio_get_latency(AudioState *as, JNIEnv *env) {
    if (!as) {
        return 0;
    }
    
    // TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —á–µ—Ä–µ–∑ audio_render_android
    // –í—ã–∑–≤–∞—Ç—å AudioTrack.getLatency() —á–µ—Ä–µ–∑ JNI
    // –ü–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
    return as->audio_latency_ms;
}

// === üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: AVSYNC IMPLEMENTATION - –®–ê–ì 4 ===

/// –ü–æ–ª—É—á–∏—Ç—å monotonic time –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö
static inline uint64_t now_ms(void) {
    return av_gettime() / 1000;  // –º–∏–∫—Ä–æ—Å–µ–∫—É–Ω–¥—ã ‚Üí –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥—ã
}

// üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: AVSYNC CODE DIFF - –®–ê–ì 20.1: Audio clock fix
// ‚úÖ Audio clock = AudioTrack.getPlaybackHeadPosition()
// ‚ùå PTS –±–æ–ª—å—à–µ –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–∞–∫ master clock
// üìå PTS –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –¥–ª—è –Ω–∞—á–∞–ª—å–Ω–æ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏, –∑–∞—Ç–µ–º playbackHead = –∏—Å—Ç–æ—á–Ω–∏–∫ –ø—Ä–∞–≤–¥—ã

/// –ü—Ä–æ–≤–µ—Ä–∏—Ç—å audio stall (Huawei / HiSilicon case)
///
/// @param as –°–æ—Å—Ç–æ—è–Ω–∏–µ –∞—É–¥–∏–æ
void audio_check_stall(AudioState *as) {
    if (!as || !as->clock.valid) {
        return;
    }
    
    // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: AUDIO CLOCK SOURCE FIX - –®–ê–ì 16: –ò—Å–ø–æ–ª—å–∑—É–µ–º last_update_us (–º–∏–∫—Ä–æ—Å–µ–∫—É–Ω–¥—ã)
    int64_t now_us = av_gettime_relative();
    double dt = (double)(now_us - as->clock.last_update_us) / 1000000.0;  // microseconds ‚Üí seconds
    if (dt > 0.5) {  // 500ms –±–µ–∑ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è ‚Üí stall
        ALOGW("üö® AudioClock: STALL detected (no update for %.3f sec)", dt);
        
        // –≠–º–∏—Ç–∏–º —Å–æ–±—ã—Ç–∏–µ (–±—É–¥–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω–æ –≤ native_player_jni.c)
        // native_player_emit_diagnostic_event("AUDIO_STALLED");
    }
}

/// –ü–æ–ø—ã—Ç–∞—Ç—å—Å—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å AudioTrack –ø–æ—Å–ª–µ stall (one-shot recovery)
///
/// @param as –°–æ—Å—Ç–æ—è–Ω–∏–µ –∞—É–¥–∏–æ
void audio_try_recover(AudioState *as) {
    if (!as || !as->audio_render.audio_track) {
        return;
    }
    
    ALOGI("üîÅ AudioClock: Attempting recovery from stall");
    
    // Stop ‚Üí Flush ‚Üí Play (one-shot recovery)
    audio_render_stop(&as->audio_render);
    audio_render_flush(&as->audio_render);
    audio_render_start(&as->audio_render);
    
    // –°–±—Ä–∞—Å—ã–≤–∞–µ–º last_update_us
    as->clock.last_update_us = av_gettime_relative();
    
    ALOGI("‚úÖ AudioClock: Recovery attempt complete");
}

/// üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: AUDIO CLOCK SOURCE FIX - –®–ê–ì 16.5: Audio stall detection
///
/// @param c AudioClock
/// @return 1 –µ—Å–ª–∏ stalled, 0 –µ—Å–ª–∏ running
int audio_clock_is_stalled(AudioClock *c) {
    if (!c || !c->valid) {
        return 1;
    }
    
    // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: AUDIO CLOCK SOURCE FIX - –®–ê–ì 16: –ò—Å–ø–æ–ª—å–∑—É–µ–º last_update_us (–º–∏–∫—Ä–æ—Å–µ–∫—É–Ω–¥—ã)
    int64_t now_us = av_gettime_relative();
    double dt = (double)(now_us - c->last_update_us) / 1000000.0;  // microseconds ‚Üí seconds
    return dt > 0.5; // 500ms
}

// === üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: AVSYNC IMPLEMENTATION - –®–ê–ì 4: ASSERT-—ã ===

/// –ü—Ä–æ–≤–µ—Ä–∏—Ç—å ASSERT-—ã –¥–ª—è audio clock (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ)
///
/// ASSERT(audio_clock >= last_audio_clock - 0.001);
/// ASSERT(!(master == AUDIO && !audio_valid));
void audio_clock_assert(AudioState *as, void *ctx_ptr) {
    PlayerContext *ctx = (PlayerContext *)ctx_ptr;
    if (!as || !ctx) {
        return;
    }
    
    #ifdef DEBUG
    // 1. ASSERT(!isnan(audio_clock))
    if (as->clock.valid && isnan(as->clock.clock)) {
        ALOGE("‚ùå AVSYNC_ASSERT FAILED: audio_clock is NAN (FATAL)");
        abort(); // üî• FATAL –≤ debug
    }
    
    // 2. ASSERT(audio_clock >= 0)
    if (as->clock.valid && as->clock.clock < 0.0) {
        ALOGE("‚ùå AVSYNC_ASSERT FAILED: audio_clock < 0 (%.3f) (FATAL)", as->clock.clock);
        abort(); // üî• FATAL –≤ debug
    }
    
    // 3. ASSERT(audio_clock monotonic)
    static double last_audio_clock = 0.0;
    if (as->clock.valid && !isnan(as->clock.clock) && as->clock.clock < last_audio_clock - 0.001) {
        ALOGE("‚ùå AVSYNC_ASSERT FAILED: audio_clock regression (%.3f < %.3f) (FATAL)", 
              as->clock.clock, last_audio_clock);
        abort(); // üî• FATAL –≤ debug
    }
    if (as->clock.valid && !isnan(as->clock.clock)) {
        last_audio_clock = as->clock.clock;
    }
    
    // 4. –ù–µ–ª—å–∑—è –±—ã—Ç—å audio-master –±–µ–∑ –≤–∞–ª–∏–¥–Ω–æ–≥–æ –∞—É–¥–∏–æ
    if (ctx->avsync.master == CLOCK_MASTER_AUDIO) {
        bool audio_valid = as->clock.valid && !audio_clock_is_stalled(&as->clock);
        if (!audio_valid) {
            ALOGE("‚ùå AVSYNC_ASSERT FAILED: master=AUDIO but audio invalid (FATAL)");
            abort(); // üî• FATAL –≤ debug
        }
    }
    #endif
}

