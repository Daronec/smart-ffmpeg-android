#include "audio_render_android.h"
#include "avsync_gate.h"  // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: AVSYNC-IMPLEMENTATION
#include "ffmpeg_player.h"  // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: –¥–ª—è AudioStateEnum (AUDIO_DEAD, AUDIO_READY, etc.)
#include <android/log.h>
#include <string.h>

#define LOG_TAG "AudioRender"
#define LOGE(...) __android_log_print(ANDROID_LOG_ERROR, LOG_TAG, __VA_ARGS__)
#define LOGI(...) __android_log_print(ANDROID_LOG_INFO,  LOG_TAG, __VA_ARGS__)
#define ALOGW(...) __android_log_print(ANDROID_LOG_WARN, LOG_TAG, __VA_ARGS__)
#define ALOGI(...) __android_log_print(ANDROID_LOG_INFO, LOG_TAG, __VA_ARGS__)
#define ALOGE(...) __android_log_print(ANDROID_LOG_ERROR, LOG_TAG, __VA_ARGS__)

/// –ü–æ–ª—É—á–∏—Ç—å JNIEnv –∏–∑ JavaVM
static JNIEnv *get_env(JavaVM *jvm) {
    JNIEnv *env = NULL;
    if ((*jvm)->GetEnv(jvm, (void **) &env, JNI_VERSION_1_6) != JNI_OK) {
        (*jvm)->AttachCurrentThread(jvm, &env, NULL);
    }
    return env;
}

bool audio_render_init(AudioRenderAndroid *ar,
                       JavaVM *jvm,
                       int sample_rate,
                       int channels) {
    memset(ar, 0, sizeof(*ar));
    
    ar->jvm = jvm;
    ar->sample_rate = sample_rate;
    ar->channels = channels;
    ar->bytes_per_sample = 2; // PCM 16-bit
    
    JNIEnv *env = get_env(jvm);
    if (!env) {
        LOGE("Failed to get JNIEnv");
        return false;
    }
    
    // –ù–∞—Ö–æ–¥–∏–º –∫–ª–∞—Å—Å AudioTrack
    jclass at_cls = (*env)->FindClass(env, "android/media/AudioTrack");
    if (!at_cls) {
        LOGE("AudioTrack class not found");
        return false;
    }
    
    // –ü–æ–ª—É—á–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –±—É—Ñ–µ—Ä–∞
    // static int getMinBufferSize(int sampleRateInHz, int channelConfig, int audioFormat)
    jmethodID get_min_buf = (*env)->GetStaticMethodID(
        env, at_cls, "getMinBufferSize",
        "(III)I"
    );
    
    if (!get_min_buf) {
        LOGE("getMinBufferSize method not found");
        (*env)->DeleteLocalRef(env, at_cls);
        return false;
    }
    
    // –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∫–∞–Ω–∞–ª–æ–≤
    // CHANNEL_OUT_MONO = 4, CHANNEL_OUT_STEREO = 12
    int channel_config = (channels == 1) ? 4 : 12;
    int audio_format = 2; // ENCODING_PCM_16BIT
    
    jint min_buf = (*env)->CallStaticIntMethod(
        env, at_cls, get_min_buf,
        sample_rate, channel_config, audio_format
    );
    
    if (min_buf <= 0) {
        LOGE("Invalid min buffer size: %d", min_buf);
        (*env)->DeleteLocalRef(env, at_cls);
        return false;
    }
    
    // –ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä AudioTrack
    // AudioTrack(streamType, sampleRateInHz, channelConfig, audioFormat, bufferSizeInBytes, mode)
    jmethodID ctor = (*env)->GetMethodID(
        env, at_cls, "<init>",
        "(IIIIII)V"
    );
    
    if (!ctor) {
        LOGE("AudioTrack constructor not found");
        (*env)->DeleteLocalRef(env, at_cls);
        return false;
    }
    
    // –®–∞–≥ 31.4: Low-latency AudioTrack config
    // bufferSize = min * 2 (–Ω–µ –±–æ–ª—å—à–µ, —á—Ç–æ–±—ã –º–∏–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ª–∞–≥)
    int buffer_size = min_buf * 2;
    
    // –°–æ–∑–¥–∞—ë–º AudioTrack
    // STREAM_MUSIC = 3, MODE_STREAM = 1
    jobject track = (*env)->NewObject(
        env, at_cls, ctor,
        3,              // STREAM_MUSIC
        sample_rate,
        channel_config,
        audio_format,
        buffer_size,    // –®–∞–≥ 31.4: –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –±—É—Ñ–µ—Ä–∞
        1               // MODE_STREAM
    );
    
    if (!track) {
        LOGE("Failed to create AudioTrack");
        (*env)->DeleteLocalRef(env, at_cls);
        return false;
    }
    
    // –°–æ—Ö—Ä–∞–Ω—è–µ–º global ref
    ar->audio_track = (*env)->NewGlobalRef(env, track);
    (*env)->DeleteLocalRef(env, track);
    
    // –ü–æ–ª—É—á–∞–µ–º method IDs
    ar->write_mid = (*env)->GetMethodID(env, at_cls, "write", "([BII)I");
    ar->play_mid = (*env)->GetMethodID(env, at_cls, "play", "()V");
    ar->pause_mid = (*env)->GetMethodID(env, at_cls, "pause", "()V");
    ar->stop_mid = (*env)->GetMethodID(env, at_cls, "stop", "()V");
    ar->release_mid = (*env)->GetMethodID(env, at_cls, "release", "()V");
    ar->get_play_state_mid = (*env)->GetMethodID(env, at_cls, "getPlayState", "()I");
    
    // –®–∞–≥ 26.1: getPlaybackHeadPosition –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ audio clock
    // –°–æ—Ö—Ä–∞–Ω—è–µ–º method ID –¥–ª—è getPlaybackHeadPosition (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
    // –ü–æ–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º samples_written –¥–ª—è —Ä–∞—Å—á—ë—Ç–∞ clock
    
    (*env)->DeleteLocalRef(env, at_cls);
    
    if (!ar->write_mid || !ar->play_mid || !ar->pause_mid || 
        !ar->stop_mid || !ar->release_mid || !ar->get_play_state_mid) {
        LOGE("Failed to get AudioTrack method IDs");
        audio_render_release(ar);
        return false;
    }
    
    LOGI("AudioTrack initialized (%d Hz, %d ch, buffer=%d bytes) - Low-latency",
         sample_rate, channels, buffer_size);
    
    return true;
}

void audio_render_start(AudioRenderAndroid *ar) {
    if (!ar->audio_track || ar->started) {
        return;
    }
    
    JNIEnv *env = get_env(ar->jvm);
    if (!env) {
        LOGE("Failed to get JNIEnv in audio_render_start");
        return;
    }
    
    // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: AUDIOFOCUS ASSERT - –ø—Ä–æ–≤–µ—Ä—è–µ–º audio focus –ø–µ—Ä–µ–¥ AudioTrack.play()
    // –ù–∞ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞—Ö (Huawei/HiSilicon) AudioTrack –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —Å–∏—Å—Ç–µ–º–æ–π
    // –µ—Å–ª–∏ audio focus –Ω–µ –ø–æ–ª—É—á–µ–Ω –∏–ª–∏ –≥—Ä–æ–º–∫–æ—Å—Ç—å = 0%
    // –≠—Ç–æ –Ω–µ –æ—à–∏–±–∫–∞, –Ω–æ –≤–∞–∂–Ω–æ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ silent playback
    LOGI("üîä AUDIOFOCUS ASSERT: AudioTrack.play() called (audio focus should be requested by app)");
    LOGI("   If audio focus not gained, AudioTrack may be stopped by Android AudioSystem");
    LOGI("   Error -2103464049 (onAudioException) indicates system stopped AudioTrack");
    
    (*env)->CallVoidMethod(env, ar->audio_track, ar->play_mid);
    
    if ((*env)->ExceptionCheck(env)) {
        LOGE("‚ùå Exception in AudioTrack.play() - AudioSystem may have stopped AudioTrack");
        LOGE("   This can happen if: volume=0%%, audio focus not gained, or OEM policy");
        (*env)->ExceptionClear(env);
        
        // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: AudioState Contract (RFC v1) - —Ç–æ—á–∫–∞ –ø–µ—Ä–µ—Ö–æ–¥–∞ 5Ô∏è‚É£ AUDIO_STOPPED_BY_SYSTEM
        // onAudioException –ø—Ä–∏ AudioTrack.play() ‚Üí AudioTrack –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —Å–∏—Å—Ç–µ–º–æ–π
        // –ù—É–∂–µ–Ω –¥–æ—Å—Ç—É–ø –∫ PlayerContext –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è audio_state
        // (–≠—Ç–æ –±—É–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –≤ audio_render_thread –ø—Ä–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–∏ frozen playbackHead)
        return;
    }
    
    // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: AUDIO-NATIVE Contract - –ø—Ä–æ–≤–µ—Ä—è–µ–º getPlayState() == PLAYSTATE_PLAYING
    // audio_clock updates ‚â† playing
    // Clock –º–æ–∂–µ—Ç —Ç–∏–∫–∞—Ç—å –¥–∞–∂–µ –µ—Å–ª–∏ AudioTrack –Ω–µ –≤—ã—à–µ–ª –≤ PLAYSTATE_PLAYING
    // –¢–û–õ–¨–ö–û –ø–æ—Å–ª–µ getPlayState() == PLAYSTATE_PLAYING –º–æ–∂–Ω–æ –≥–æ–≤–æ—Ä–∏—Ç—å, —á—Ç–æ –∞—É–¥–∏–æ —Ä–µ–∞–ª—å–Ω–æ –∏–≥—Ä–∞–µ—Ç
    int play_state = (*env)->CallIntMethod(env, ar->audio_track, ar->get_play_state_mid);
    
    if ((*env)->ExceptionCheck(env)) {
        LOGE("‚ùå Exception in AudioTrack.getPlayState()");
        (*env)->ExceptionClear(env);
        return;
    }
    
    // PLAYSTATE_PLAYING = 3 (android.media.AudioTrack)
    const int PLAYSTATE_PLAYING = 3;
    
    // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: AUDIO-ASSERTS A1 - ASSERT: AudioTrack.play() –ü–†–ò–ù–Ø–¢
    // ‚ùå –ë–ï–ó –≠–¢–û–ì–û —Å–æ–±—ã—Ç–∏—è Flutter –ù–ï –ò–ú–ï–ï–¢ –ü–†–ê–í–ê –¥–æ–≤–µ—Ä—è—Ç—å audio_clock
    if (play_state != PLAYSTATE_PLAYING) {
        LOGE("‚ùå AUDIO_ASSERT A1 FAILED: AudioTrack.getPlayState() = %d (expected PLAYSTATE_PLAYING=3)", play_state);
        LOGE("   AudioTrack.play() called but state is not PLAYING");
        LOGE("   This means audio will NOT be heard, even if audio_clock updates");
        LOGE("   FATAL: Cannot continue playback without valid AudioTrack state");
        
        // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: –≠–º–∏—Ç–∏–º ERROR —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        if (ar->player_ctx) {
            PlayerContext *ctx = (PlayerContext *)ar->player_ctx;
            ctx->audio_state = AUDIO_DEAD; // –¢–µ—Ä–º–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
            extern void native_player_emit_audio_state_event(const char *state);
            native_player_emit_audio_state_event("dead");
        }
        
        // –ù–ï —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º ar->started = true, —Ç–∞–∫ –∫–∞–∫ AudioTrack –Ω–µ –≤ PLAYING
        // ‚ùå FATAL: –ù–µ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º playback –±–µ–∑ –≤–∞–ª–∏–¥–Ω–æ–≥–æ AudioTrack
        return;
    }
    
    ar->started = true;
    LOGI("‚úÖ AudioTrack.play() accepted: getPlayState() == PLAYSTATE_PLAYING");
    LOGI("   Audio is now REAL playing (not just clock updates)");
    
    // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: AudioState Contract (RFC v1) - —Ç–æ—á–∫–∞ –ø–µ—Ä–µ—Ö–æ–¥–∞ 4Ô∏è‚É£ AUDIO_PLAYING
    // AudioTrack.play() –í–´–ó–í–ê–ù –ò –ü–†–ò–ù–Ø–¢ (getPlayState() == PLAYSTATE_PLAYING)
    // –≠–º–∏—Ç–∏–º audioStarted —Å–æ–±—ã—Ç–∏–µ –¢–û–õ–¨–ö–û –∑–¥–µ—Å—å
    if (ar->player_ctx) {
        PlayerContext *ctx = (PlayerContext *)ar->player_ctx;
        // –ü–µ—Ä–µ—Ö–æ–¥ –≤ AUDIO_PLAYING —Ç–æ–ª—å–∫–æ –∏–∑ AUDIO_READY (buffer primed)
        if (ctx->audio_state == AUDIO_READY) {
            ctx->audio_state = AUDIO_PLAYING;
            ALOGI("üéß AudioState: AUDIO_READY ‚Üí AUDIO_PLAYING (AudioTrack.getPlayState() == PLAYSTATE_PLAYING)");
            
            // üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX: AUDIO CLOCK SOURCE FIX - –ù–ï —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º AVSYNC valid –∑–¥–µ—Å—å
            // AVSYNC valid –±—É–¥–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ —É—Å–ø–µ—à–Ω–æ–≥–æ write() –∫–æ–≥–¥–∞ clock_valid = true
            // –≠—Ç–æ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ AVSYNC –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≤–∞–ª–∏–¥–Ω—ã–π PTS-based clock, –∞ –Ω–µ playbackHeadPosition
            
            extern void native_player_emit_audio_state_event(const char *state);
            native_player_emit_audio_state_event("playing");
        } else if (ctx->audio_state == AUDIO_INITIALIZED) {
            // –ï—Å–ª–∏ –µ—â—ë –Ω–µ –≥–æ—Ç–æ–≤ (buffer –Ω–µ primed), –∂–¥—ë–º AUDIO_READY
            LOGI("üéß AudioState: AUDIO_INITIALIZED (waiting for buffer primed ‚Üí AUDIO_READY)");
        }
    }
}

void audio_render_pause(AudioRenderAndroid *ar) {
    if (!ar->audio_track || !ar->started) {
        return;
    }
    
    JNIEnv *env = get_env(ar->jvm);
    if (!env) {
        return;
    }
    
    (*env)->CallVoidMethod(env, ar->audio_track, ar->pause_mid);
    
    if ((*env)->ExceptionCheck(env)) {
        LOGE("Exception in AudioTrack.pause()");
        (*env)->ExceptionClear(env);
    }
    
    ar->started = false;
    LOGI("AudioTrack paused");
}

void audio_render_stop(AudioRenderAndroid *ar) {
    if (!ar->audio_track) {
        return;
    }
    
    JNIEnv *env = get_env(ar->jvm);
    if (!env) {
        return;
    }
    
    (*env)->CallVoidMethod(env, ar->audio_track, ar->stop_mid);
    
    if ((*env)->ExceptionCheck(env)) {
        LOGE("Exception in AudioTrack.stop()");
        (*env)->ExceptionClear(env);
    }
    
    ar->started = false;
    LOGI("AudioTrack stopped");
}

int audio_render_write(AudioRenderAndroid *ar,
                       const uint8_t *data,
                       int size) {
    if (!ar->audio_track || !ar->started || !data || size <= 0) {
        return 0;
    }
    
    JNIEnv *env = get_env(ar->jvm);
    if (!env) {
        return 0;
    }
    
    // –°–æ–∑–¥–∞—ë–º byte array
    jbyteArray array = (*env)->NewByteArray(env, size);
    if (!array) {
        LOGE("Failed to allocate byte array");
        return 0;
    }
    
    // –ö–æ–ø–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
    (*env)->SetByteArrayRegion(
        env, array, 0, size, (const jbyte *) data
    );
    
    // –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ AudioTrack
    jint written = (*env)->CallIntMethod(
        env, ar->audio_track, ar->write_mid,
        array, 0, size
    );
    
    (*env)->DeleteLocalRef(env, array);
    
    if ((*env)->ExceptionCheck(env)) {
        LOGE("Exception in AudioTrack.write()");
        (*env)->ExceptionClear(env);
        return 0;
    }
    
    if (written < 0) {
        LOGE("AudioTrack.write() returned error: %d", written);
        return 0;
    }
    
    return written;
}

void audio_render_release(AudioRenderAndroid *ar) {
    if (!ar->audio_track) {
        return;
    }
    
    JNIEnv *env = get_env(ar->jvm);
    if (env) {
        // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∏ –æ—Å–≤–æ–±–æ–∂–¥–∞–µ–º
        (*env)->CallVoidMethod(env, ar->audio_track, ar->stop_mid);
        (*env)->CallVoidMethod(env, ar->audio_track, ar->release_mid);
        
        if ((*env)->ExceptionCheck(env)) {
            LOGE("Exception in AudioTrack release");
            (*env)->ExceptionClear(env);
        }
        
        (*env)->DeleteGlobalRef(env, ar->audio_track);
    }
    
    ar->audio_track = NULL;
    ar->started = false;
    
    LOGI("AudioTrack released");
}

int64_t audio_render_get_playback_head(AudioRenderAndroid *ar) {
    if (!ar->audio_track) {
        return 0;
    }
    
    JNIEnv *env = get_env(ar->jvm);
    if (!env) {
        return 0;
    }
    
    // –®–∞–≥ 31.3: –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ audio time —á–µ—Ä–µ–∑ getPlaybackHeadPosition
    jclass at_cls = (*env)->GetObjectClass(env, ar->audio_track);
    if (!at_cls) {
        return 0;
    }
    
    jmethodID get_pos_mid = (*env)->GetMethodID(env, at_cls, "getPlaybackHeadPosition", "()I");
    if (!get_pos_mid) {
        (*env)->DeleteLocalRef(env, at_cls);
        return 0;
    }
    
    jint position = (*env)->CallIntMethod(env, ar->audio_track, get_pos_mid);
    
    (*env)->DeleteLocalRef(env, at_cls);
    
    if ((*env)->ExceptionCheck(env)) {
        LOGE("Exception in AudioTrack.getPlaybackHeadPosition()");
        (*env)->ExceptionClear(env);
        return 0;
    }
    
    return (int64_t)position;
}

/// –ü–æ–ª—É—á–∏—Ç—å audio latency (–®–ê–ì 4)
int audio_render_get_latency(AudioRenderAndroid *ar) {
    if (!ar->audio_track) {
        return 0;
    }
    
    JNIEnv *env = get_env(ar->jvm);
    if (!env) {
        return 0;
    }
    
    // –®–ê–ì 4: –ü–æ–ª—É—á–µ–Ω–∏–µ latency —á–µ—Ä–µ–∑ AudioTrack.getLatency()
    jclass at_cls = (*env)->GetObjectClass(env, ar->audio_track);
    if (!at_cls) {
        return 0;
    }
    
    jmethodID get_latency_mid = (*env)->GetMethodID(env, at_cls, "getLatency", "()I");
    if (!get_latency_mid) {
        (*env)->DeleteLocalRef(env, at_cls);
        return 0;
    }
    
    jint latency_ms = (*env)->CallIntMethod(env, ar->audio_track, get_latency_mid);
    
    (*env)->DeleteLocalRef(env, at_cls);
    
    if ((*env)->ExceptionCheck(env)) {
        LOGE("Exception in AudioTrack.getLatency()");
        (*env)->ExceptionClear(env);
        return 0;
    }
    
    return (int)latency_ms;
}

void audio_render_flush(AudioRenderAndroid *ar) {
    if (!ar->audio_track) {
        return;
    }
    
    JNIEnv *env = get_env(ar->jvm);
    if (!env) {
        return;
    }
    
    // –®–∞–≥ 31.8: Flush AudioTrack (—Ç–æ–ª—å–∫–æ –ø—Ä–∏ seek)
    jclass at_cls = (*env)->GetObjectClass(env, ar->audio_track);
    if (!at_cls) {
        return;
    }
    
    jmethodID flush_mid = (*env)->GetMethodID(env, at_cls, "flush", "()V");
    if (flush_mid) {
        (*env)->CallVoidMethod(env, ar->audio_track, flush_mid);
        
        if ((*env)->ExceptionCheck(env)) {
            LOGE("Exception in AudioTrack.flush()");
            (*env)->ExceptionClear(env);
        }
    }
    
    (*env)->DeleteLocalRef(env, at_cls);
    
    LOGI("AudioTrack flushed");
}

/// –ü–æ–ª—É—á–∏—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è AudioTrack
///
/// @param ar –ê—É–¥–∏–æ—Ä–µ–Ω–¥–µ—Ä
/// @return PLAYSTATE_STOPPED (1), PLAYSTATE_PAUSED (2), PLAYSTATE_PLAYING (3), –∏–ª–∏ -1 –ø—Ä–∏ –æ—à–∏–±–∫–µ
int audio_render_get_play_state(AudioRenderAndroid *ar) {
    if (!ar || !ar->audio_track) {
        return -1;
    }
    
    JNIEnv *env = get_env(ar->jvm);
    if (!env) {
        return -1;
    }
    
    if (!ar->get_play_state_mid) {
        // –ü–æ–ª—É—á–∞–µ–º method ID –µ—Å–ª–∏ –µ—â—ë –Ω–µ –ø–æ–ª—É—á–µ–Ω
        jclass at_cls = (*env)->GetObjectClass(env, ar->audio_track);
        if (!at_cls) {
            return -1;
        }
        
        ar->get_play_state_mid = (*env)->GetMethodID(env, at_cls, "getPlayState", "()I");
        (*env)->DeleteLocalRef(env, at_cls);
        
        if (!ar->get_play_state_mid) {
            LOGE("Failed to get getPlayState method ID");
            return -1;
        }
    }
    
    jint state = (*env)->CallIntMethod(env, ar->audio_track, ar->get_play_state_mid);
    
    if ((*env)->ExceptionCheck(env)) {
        LOGE("Exception in AudioTrack.getPlayState()");
        (*env)->ExceptionClear(env);
        return -1;
    }
    
    return (int)state;
}

